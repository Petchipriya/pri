{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the datasret\n",
    "filepath='Response750.csv'\n",
    "personality=pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check first 5 datas\n",
    "#personality.head()\n",
    "#Describing dataset\n",
    "#desc=personality.describe().transpose()\n",
    "#print(desc)\n",
    "#Describing shape\n",
    "#personality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping target column\n",
    "X = personality.drop('Q31',axis=1)\n",
    "y = personality['Q31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset to training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Petchipriya\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the trainig dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "#scaler.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Petchipriya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Petchipriya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set results\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(150,150,150),max_iter=1000)\n",
    "mlp.fit(X_train,y_train)\n",
    "MLPClassifier(activation='sigmoid', batch_size=10, \n",
    "      # hidden_layer_sizes=(13, 13, 13), \n",
    "       learning_rate_init=0.01, \n",
    "      # max_iter=500, \n",
    "       solver='adam')\n",
    "predictions = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#print(confusion_matrix(y_test,predictions))\n",
    "#mat=confusion_matrix(y_test,predictions)\n",
    "#import numpy as np\n",
    "#print(np.sum(mat.diagonal())/np.sum(mat)*100)\n",
    "#pre=mlp.predict([[4,3,1,2,3,1,2,2,2,1,1,2,1,2,2,2,2,2,1,1,2,2,2,2,2,1,2,2,2,2]])\n",
    "#print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model to disk\n",
    "pickle.dump(mlp,open(\"mlp.pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
